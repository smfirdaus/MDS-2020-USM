{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models with LDA (2 class, (n=1)components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "from pandas_profiling import ProfileReport\n",
    "#import tkinter\n",
    "from matplotlib import pyplot as plt\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import scikitplot as skplt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "#from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TKAgg')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset, Replace Class, Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y class [0 1]\n",
      "yd class [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Load 2 datasets\n",
    "dfC = pd.read_csv(\"MeterC\",sep='\\t',header=None, names=['flatr','symm','crossf','v1','v2','v3','v4','sos1','sos2','sos3','sos4','ss11','ss12','ss21','ss22','ss31','ss32','ss41','ss42','sq11','sq12','sq21','sq22','sq31','sq32','sq41','sq42','gain11','gain12','gain21','gain22','gain31','gain32','gain41','gain42','tt11','tt12','tt21','tt22','tt31','tt32','tt41','tt42','class'])\n",
    "dfD = pd.read_csv(\"MeterD\",sep='\\t',header=None, names=['flatr','symm','crossf','v1','v2','v3','v4','sos1','sos2','sos3','sos4','ss11','ss12','ss21','ss22','ss31','ss32','ss41','ss42','sq11','sq12','sq21','sq22','sq31','sq32','sq41','sq42','gain11','gain12','gain21','gain22','gain31','gain32','gain41','gain42','tt11','tt12','tt21','tt22','tt31','tt32','tt41','tt42','class'])\n",
    "\n",
    "# replace class\n",
    "dfC['class'].replace(1, 0,inplace=True)\n",
    "dfC['class'].replace(2, 1,inplace=True)\n",
    "dfC['class'].replace(3, 1,inplace=True)\n",
    "dfC['class'].replace(4, 1,inplace=True)\n",
    "dfD['class'].replace(1, 0,inplace=True)\n",
    "dfD['class'].replace(2, 1,inplace=True)\n",
    "dfD['class'].replace(3, 1,inplace=True)\n",
    "dfD['class'].replace(4, 1,inplace=True)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "features = ['flatr','symm','crossf','v1','v2','v3','v4','sos1','sos2','sos3','sos4','ss11','ss12','ss21','ss22','ss31','ss32','ss41','ss42','sq11','sq12','sq21','sq22','sq31','sq32','sq41','sq42','gain11','gain12','gain21','gain22','gain31','gain32','gain41','gain42','tt11','tt12','tt21','tt22','tt31','tt32','tt41','tt42']\n",
    "\n",
    "X = dfC.loc[:, features].values\n",
    "y = dfC.loc[:,['class']].values\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "#process for dataset D\n",
    "Xd = dfD.loc[:, features].values\n",
    "yd = dfD.loc[:,['class']].values\n",
    "Xd = scaler.fit_transform(Xd)\n",
    "\n",
    "#change the shape of y from column array to horizontal array or (n_samples, ) using ravel().\n",
    "y = y.ravel()\n",
    "print('y class',dfC['class'].unique())\n",
    "yd = yd.ravel()\n",
    "print('yd class',dfD['class'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "lda = LDA(n_components=1)\n",
    "X = lda.fit_transform(X,y)\n",
    "\n",
    "lda1 = LDA(n_components=1)\n",
    "Xd = lda1.fit_transform(Xd,yd)\n",
    "\n",
    "print(np.cumsum(lda.explained_variance_ratio_))\n",
    "print(np.cumsum(lda1.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LDA1</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.867333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.854629</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.314498</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.320894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1.550675</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         LDA1  class\n",
       "176  0.867333      1\n",
       "177  0.854629      1\n",
       "178  1.314498      1\n",
       "179  1.320894      1\n",
       "180  1.550675      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfX = pd.DataFrame(X)\n",
    "dfX['class']=y\n",
    "dfX.columns = ['LDA1','class']\n",
    "dfX.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate using K-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier |  5fold |  10fold | Accuracy_5fold | Accuracy_10fold |  F1micro5, F1macro5, F1avg5 | F1micro10,F1macro10, F1avg10\n",
      "------------------------------------------------------------------------------------------------------------------------------\n",
      "     Bayes |   0.84 |    0.84 |          0.889 |          0.889  |     0.854    0.889    0.885 |     0.856    0.889    0.886\n",
      "       KNN |  0.818 |   0.818 |          0.839 |          0.856  |     0.798    0.839    0.837 |     0.818    0.856    0.854\n",
      "       SVM |  0.851 |   0.856 |          0.894 |          0.894  |     0.858    0.894    0.889 |      0.86    0.894     0.89\n",
      "        RF |  0.824 |   0.835 |          0.839 |          0.867  |     0.795    0.839    0.836 |     0.832    0.867    0.865\n",
      "       ANN |   0.84 |    0.84 |          0.833 |          0.867  |      0.79    0.833    0.831 |     0.832    0.867    0.865\n"
     ]
    }
   ],
   "source": [
    "#classifier models\n",
    "clfNB = GaussianNB()\n",
    "clfKNN = KNeighborsClassifier(n_neighbors=5)\n",
    "clfSVM = svm.SVC(kernel='linear', C=1)\n",
    "clfRF = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clfNN = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(15,), random_state=1, max_iter=2500)\n",
    "\n",
    "n_folds = [5,10]\n",
    "targets = [clfNB,clfKNN,clfSVM,clfRF,clfNN]\n",
    "models = ['Bayes','KNN','SVM','RF','ANN']\n",
    "# Computing training scores to get insights on how different parameter settings impact the overfitting/underfitting trade-off. \n",
    "# However computing the scores on the training set can be computationally expensive and is not strictly required \n",
    "# to select the parameters that yield the best generalization performance\n",
    "\n",
    "print(\"\\n{:>10} | {:>6} | {:>7} | {:>14} | {:>14} | {:>9},{:>9},{:>7} | {:>9},{:>9},{:>8}\".format('Classifier', '5fold', '10fold', 'Accuracy_5fold','Accuracy_10fold','F1micro5','F1macro5','F1avg5','F1micro10','F1macro10','F1avg10'))\n",
    "print('------------------------------------------------------------------------------------------------------------------------------')\n",
    "for i,j in zip(targets,models):\n",
    "    # K-fold cross validation for the training dataset (Dataset C)\n",
    "    cv5 = cross_validate(i, X, y, cv=5, return_train_score=True) # == cvScore = cross_val_score(i, X, y, cv=5)\n",
    "    cv10 = cross_validate(i, X, y, cv=10, return_train_score=True)    \n",
    "    cv5mean = np.round(cv5['test_score'].mean(),decimals=3)\n",
    "    cv10mean = np.round(cv10['test_score'].mean(),decimals=3)\n",
    "    # K-fold cross validation and predict for the validation dataset (Dataset D)\n",
    "    y_pred5 = cross_val_predict(i, Xd, yd, cv=5)\n",
    "    y_pred10 = cross_val_predict(i, Xd, yd, cv=10)\n",
    "    # Evaluate performance for validation score\n",
    "    accuracy5 = np.round(accuracy_score(yd, y_pred5),decimals=3)\n",
    "    accuracy10 = np.round(accuracy_score(yd, y_pred10),decimals=3)\n",
    "    f1micro5 = np.round(f1_score(yd, y_pred5, average='macro'),decimals=3)\n",
    "    f1macro5 = np.round(f1_score(yd, y_pred5, average='micro'),decimals=3)\n",
    "    f1avg5 = np.round(f1_score(yd, y_pred5, average='weighted'),decimals=3)\n",
    "    f1micro10 = np.round(f1_score(yd, y_pred10, average='macro'),decimals=3)\n",
    "    f1macro10 = np.round(f1_score(yd, y_pred10, average='micro'),decimals=3)\n",
    "    f1avg10 = np.round(f1_score(yd, y_pred10, average='weighted'),decimals=3)\n",
    "    print(\"{:>10} | {:>6} | {:>7} | {:>14} | {:>14}  | {:>9}{:>9}{:>9} | {:>9}{:>9}{:>9}\".format(j,cv5mean,cv10mean,accuracy5,accuracy10,f1micro5,f1macro5,f1avg5,f1micro10,f1macro10,f1avg10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate using Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into train and test set\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, y, test_size=0.20, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier |  AccuracyC |  AccuracyD |  F1microC, F1macroC, F1avgC |  F1microD, F1macroD,  F1avgD\n",
      "-------------------------------------------------------------------------------------------------\n",
      "     Bayes |      0.892 |      0.889 |     0.801    0.892    0.877 |      0.86    0.889    0.887\n",
      "       KNN |      0.811 |      0.861 |     0.733    0.811    0.815 |     0.836    0.861    0.864\n",
      "       SVM |      0.892 |        0.9 |     0.801    0.892    0.877 |     0.877      0.9      0.9\n",
      "        RF |      0.892 |        0.9 |     0.801    0.892    0.877 |     0.878      0.9    0.901\n",
      "       ANN |      0.892 |        0.9 |     0.801    0.892    0.877 |     0.877      0.9      0.9\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n{:>10} | {:>10} | {:>10} | {:>9},{:>9},{:>7} | {:>9},{:>9},{:>8}\".format('Classifier', 'AccuracyC','AccuracyD','F1microC','F1macroC','F1avgC','F1microD','F1macroD','F1avgD'))\n",
    "print('-------------------------------------------------------------------------------------------------')\n",
    "for i,j in zip(targets,models):\n",
    "    i.fit(X_train, Y_train) # train the model\n",
    "    accuracyC = np.round(i.score(X_test, Y_test),decimals=3) # Calc accuracy score for the training dataset (Dataset C)\n",
    "    accuracyD = np.round(i.score(Xd, yd),decimals=3) # Calc accuracy score for the validation dataset (Dataset D)\n",
    "    # Evaluate performance for validation score\n",
    "    y_predC = i.predict(X_test)\n",
    "    y_predD = i.predict(Xd)\n",
    "    f1microC = np.round(f1_score(Y_test, y_predC, average='macro'),decimals=3)\n",
    "    f1macroC = np.round(f1_score(Y_test, y_predC, average='micro'),decimals=3)\n",
    "    f1avgC = np.round(f1_score(Y_test, y_predC, average='weighted'),decimals=3)\n",
    "    f1microD = np.round(f1_score(yd, y_predD, average='macro'),decimals=3)\n",
    "    f1macroD = np.round(f1_score(yd, y_predD, average='micro'),decimals=3)\n",
    "    f1avgD = np.round(f1_score(yd, y_predD, average='weighted'),decimals=3)\n",
    "    print(\"{:>10} | {:>10} | {:>10} | {:>9}{:>9}{:>9} | {:>9}{:>9}{:>9}\".format(j,accuracyC,accuracyD,f1microC,f1macroC,f1avgC,f1microD,f1macroD,f1avgD))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Bayes Confusion Matrix for Test Set (5-fold):\n",
      " [[ 31  23]\n",
      " [  6 121]]\n",
      "\n",
      " KNN Confusion Matrix for Test Set (5-fold):\n",
      " [[ 35  19]\n",
      " [ 14 113]]\n",
      "\n",
      " SVM Confusion Matrix for Test Set (5-fold):\n",
      " [[ 34  20]\n",
      " [  7 120]]\n",
      "\n",
      " RF Confusion Matrix for Test Set (5-fold):\n",
      " [[ 35  19]\n",
      " [ 13 114]]\n",
      "\n",
      " ANN Confusion Matrix for Test Set (5-fold):\n",
      " [[ 35  19]\n",
      " [ 10 117]]\n",
      "--------------------------------------------------------\n",
      "\n",
      " Bayes Confusion Matrix for Validation Set (5-fold):\n",
      " [[ 36  15]\n",
      " [  5 124]]\n",
      "\n",
      " KNN Confusion Matrix for Validation Set (5-fold):\n",
      " [[ 35  16]\n",
      " [ 13 116]]\n",
      "\n",
      " SVM Confusion Matrix for Validation Set (5-fold):\n",
      " [[ 35  16]\n",
      " [  3 126]]\n",
      "\n",
      " RF Confusion Matrix for Validation Set (5-fold):\n",
      " [[ 34  17]\n",
      " [ 12 117]]\n",
      "\n",
      " ANN Confusion Matrix for Validation Set (5-fold):\n",
      " [[ 34  17]\n",
      " [ 13 116]]\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(targets,models):\n",
    "    # K-fold cross validation for the training dataset (Dataset C)\n",
    "    y_predC5 = cross_val_predict(i, X, y, cv=5)\n",
    "   # print(j,'Confusion Matrix for Test Set (5-fold):\\n',confusion_matrix(y, y_predC5))\n",
    "    print('\\n',j,'Confusion Matrix for Test Set (5-fold):\\n',confusion_matrix(y, y_predC5))\n",
    "    \n",
    "print('--------------------------------------------------------')\n",
    "      \n",
    "for i,j in zip(targets,models):\n",
    "    # K-fold cross validation and predict for the validation dataset (Dataset D)\n",
    "    y_predD5 = cross_val_predict(i, Xd, yd, cv=5)\n",
    "   # print(j,'Confusion Matrix for Test Set (5-fold):\\n',confusion_matrix(y, y_predC5))\n",
    "    print('\\n',j,'Confusion Matrix for Validation Set (5-fold):\\n',confusion_matrix(yd, y_predD5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
